{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled73.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMCIYMuR0xGBcRuZE39qEmJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArefPhD/General-training/blob/main/RecreatinganypictureGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iAvT4PzK11R"
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJSWXW2tK3dW"
      },
      "source": [
        "# Import MNIST data\n",
        "tf.keras.datasets.mnist.load_data(\n",
        "    path='mnist.npz'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3hqUex4LUhH"
      },
      "source": [
        "import tensorflow_datasets\n",
        "mnist = tensorflow_datasets.load('mnist')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRsOY8DxY_7X"
      },
      "source": [
        "L=mnist.get('train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31JSj0pmK55J"
      },
      "source": [
        "# Training Params\n",
        "num_steps = 500\n",
        "batch_size = 128\n",
        "learning_rate = 0.0002\n",
        "\n",
        "# Network Params\n",
        "image_dim = 784 # 28*28 pixels\n",
        "gen_hidden_dim = 256\n",
        "disc_hidden_dim = 256\n",
        "noise_dim = 100 # Noise data points\n",
        "\n",
        "# A custom initialization (see Xavier Glorot init)\n",
        "def glorot_init(shape):\n",
        "    return tf.random.normal(shape=shape, stddev=1. / tf.sqrt(shape[0] / 2.))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DpGW3z8K5zM"
      },
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    'gen_hidden1': tf.Variable(glorot_init([100, 256])),\n",
        "    'gen_out': tf.Variable(glorot_init([256, 784])),\n",
        "    'disc_hidden1': tf.Variable(glorot_init([784, 256])),\n",
        "    'disc_out': tf.Variable(glorot_init([256, 1])),\n",
        "}\n",
        "biases = {\n",
        "    'gen_hidden1': tf.Variable(tf.zeros([256])),\n",
        "    'gen_out': tf.Variable(tf.zeros([784])),\n",
        "    'disc_hidden1': tf.Variable(tf.zeros([256])),\n",
        "    'disc_out': tf.Variable(tf.zeros([1])),\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkNw1ydvLBzB"
      },
      "source": [
        "# Generator\n",
        "def generator(x):\n",
        "    hidden_layer = tf.matmul(x, weights['gen_hidden1'])\n",
        "    hidden_layer = tf.add(hidden_layer, biases['gen_hidden1'])\n",
        "    hidden_layer = tf.nn.relu(hidden_layer)\n",
        "    out_layer = tf.matmul(hidden_layer, weights['gen_out'])\n",
        "    out_layer = tf.add(out_layer, biases['gen_out'])\n",
        "    out_layer = tf.nn.sigmoid(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "\n",
        "# Discriminator\n",
        "def discriminator(x):\n",
        "    hidden_layer = tf.matmul(x, weights['disc_hidden1'])\n",
        "    hidden_layer = tf.add(hidden_layer, biases['disc_hidden1'])\n",
        "    hidden_layer = tf.nn.relu(hidden_layer)\n",
        "    out_layer = tf.matmul(hidden_layer, weights['disc_out'])\n",
        "    out_layer = tf.add(out_layer, biases['disc_out'])\n",
        "    out_layer = tf.nn.sigmoid(out_layer)\n",
        "    return out_layer\n",
        "\n",
        "# Build Networks\n",
        "# Network Inputs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChFEDJCKOCUl"
      },
      "source": [
        "tf.disable_v2_behavior()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcXIeKO1L09X"
      },
      "source": [
        "gen_input = tf.placeholder(tf.float32, shape=[None, noise_dim], name='input_noise')\n",
        "disc_input = tf.placeholder(tf.float32, shape=[None, image_dim], name='disc_input')\n",
        "\n",
        "\n",
        "# Build Generator Network\n",
        "gen_sample = generator(gen_input)\n",
        "\n",
        "# Build 2 Discriminator Networks (one from noise input, one from generated samples)\n",
        "A = discriminator(disc_input)\n",
        "B = discriminator(gen_sample)\n",
        "\n",
        "# Build Loss\n",
        "gen_loss = -tf.reduce_mean(tf.log(B))\n",
        "disc_loss = -tf.reduce_mean(tf.log(A) + tf.log(1. - B))\n",
        "\n",
        "# Build Optimizers\n",
        "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "\n",
        "# Training Variables for each optimizer\n",
        "# By default in TensorFlow, all variables are updated by each optimizer, so we\n",
        "# need to precise for each one of them the specific variables to update.\n",
        "# Generator Network Variables\n",
        "gen_vars = [weights['gen_hidden1'], weights['gen_out'],\n",
        "            biases['gen_hidden1'], biases['gen_out']]\n",
        "# Discriminator Network Variables\n",
        "disc_vars = [weights['disc_hidden1'], weights['disc_out'],\n",
        "            biases['disc_hidden1'], biases['disc_out']]\n",
        "\n",
        "# Create training operations\n",
        "train_gen = optimizer_gen.minimize(gen_loss, var_list=gen_vars)\n",
        "train_disc = optimizer_disc.minimize(disc_loss, var_list=disc_vars)\n",
        "\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OLDjqzsQXZgd"
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "dataset = tfds.load('mnist', split=['test'], as_supervised=True)\n",
        "\n",
        "array = np.vstack(tfds.as_numpy(dataset[0]))\n",
        "\n",
        "X_train = np.array(list(map(lambda x: x[0], array)))\n",
        "y_train = np.array(list(map(lambda x: x[1], array)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOu0QKF_Sqya"
      },
      "source": [
        "from google.colab import files\n",
        "upload=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7RmWXZTSnSf"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "\n",
        "L=scipy.io.loadmat('1jpg (1).mat')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1unfoS-TGlB"
      },
      "source": [
        "S=L.get('img')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRbYAFirabYX"
      },
      "source": [
        "L=S\n",
        "L=tf.reshape(L,[28, 28, 1])\n",
        "L=K.eval(L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDSbCw0XApgV"
      },
      "source": [
        "pil_img = tf.keras.preprocessing.image.array_to_img(L)\n",
        "pil_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IEJ2VQ8Bw7y"
      },
      "source": [
        "from google.colab import files\n",
        "upload=files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNvUHzLJCAfR"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hYROgrLfB9w2"
      },
      "source": [
        "Im=Image.open('image4001.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Gk3ep2l7ZT0"
      },
      "source": [
        "L.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu2XnkpqCDYQ"
      },
      "source": [
        "\n",
        "X_train[0]=L\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ik4BvPGLGu3P"
      },
      "source": [
        "pil_img.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0a08qWkggrj"
      },
      "source": [
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LD1rRz-oLGJQ"
      },
      "source": [
        "# Start Training\n",
        "# Start a new TF session\n",
        "sess = tf.Session()\n",
        "\n",
        "# Run the initializer\n",
        "sess.run(init)\n",
        "\n",
        "# Training\n",
        "for i in range(1, num_steps+1):\n",
        "    # Prepare Data\n",
        "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
        "    batch_x = X_train[0]\n",
        "    batch_x=tf.reshape(batch_x, [1, 784])\n",
        "    batch_x= K.eval(batch_x)\n",
        "    # Generate noise to feed to the generator\n",
        "    z = np.random.uniform(-1., 1., size=[batch_size, noise_dim])\n",
        "\n",
        "    # Train\n",
        "    feed_dict = {disc_input: batch_x, gen_input: z}\n",
        "    _, _, gl, dl = sess.run([train_gen, train_disc, gen_loss, disc_loss],\n",
        "                            feed_dict=feed_dict)\n",
        "    if i % 2 == 0 or i == 1:\n",
        "        print('Step %i: Generator Loss: %f, Discriminator Loss: %f' % (i, gl, dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0U1AgC5LH3H"
      },
      "source": [
        "\n",
        "# Testing\n",
        "# Generate images from noise, using the generator network.\n",
        "n = 6\n",
        "canvas = np.empty((28 * n, 28 * n))\n",
        "for i in range(n):\n",
        "    # Noise input.\n",
        "    z = np.random.uniform(-1., 1., size=[n, noise_dim])\n",
        "    # Generate image from noise.\n",
        "    g = sess.run(gen_sample, feed_dict={gen_input: z})\n",
        "    # Reverse colours for better display\n",
        "    g = -1 * (g - 1)\n",
        "    for j in range(n):\n",
        "        # Draw the generated digits\n",
        "        canvas[i * 28:(i + 1) * 28, j * 28:(j + 1) * 28] = g[j].reshape([28, 28])\n",
        "\n",
        "plt.figure(figsize=(n, n))\n",
        "plt.imshow(canvas, origin=\"upper\", cmap=\"gray\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}