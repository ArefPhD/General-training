{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Credit Fraud detection with autoencoders.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArefPhD/General-training/blob/main/Credit_Fraud_detection_with_autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEl3ncgPc0sv"
      },
      "source": [
        "\n",
        "#Credit Card Fraud Detection\n",
        "\n",
        "Example of outlier detection with autoencoders. Dataset https://www.kaggle.com/mlg-ulb/creditcardfraud from Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles).\n",
        "\n",
        "It is a highly unbalanced dataset with a very low percetnage of fraudulent credit card transactions. Our purpose is to build a classifier for detecting fraudulent transactions. In this example we will consider them as outliers an will use an autoencoder for detecting them.\n",
        "\n",
        "##Downloading of dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gT2psZNVvB9U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b780d3f-1959-404f-8a85-94c7cccbf01d"
      },
      "source": [
        "!wget -O creditfraud.zip https://www.dropbox.com/s/tl20yp9bcl56oxt/creditcardfraud.zip?dl=0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-18 22:09:40--  https://www.dropbox.com/s/tl20yp9bcl56oxt/creditcardfraud.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/tl20yp9bcl56oxt/creditcardfraud.zip [following]\n",
            "--2021-06-18 22:09:41--  https://www.dropbox.com/s/raw/tl20yp9bcl56oxt/creditcardfraud.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com/cd/0/inline/BQqvBSGNxYD_6908fKpu4UEXgw2wTWqkt6n9oYRD7r3lLnXAPUzj5x7uwv3hf9c1d8kH5fwA1xcU3njEaMdxaGSTjur7q3fxvXikcZiy8O7OtlmA0vs01isoMZeRqDid1GidSEwt70qrnXYiSbwBwOxl/file# [following]\n",
            "--2021-06-18 22:09:41--  https://ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com/cd/0/inline/BQqvBSGNxYD_6908fKpu4UEXgw2wTWqkt6n9oYRD7r3lLnXAPUzj5x7uwv3hf9c1d8kH5fwA1xcU3njEaMdxaGSTjur7q3fxvXikcZiy8O7OtlmA0vs01isoMZeRqDid1GidSEwt70qrnXYiSbwBwOxl/file\n",
            "Resolving ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com (ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:601d:15::a27d:50f\n",
            "Connecting to ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com (ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BQq3yREqIgnh8ucBpYkbWs2z3fVbPo1bYQsFnVx9n9qswuY046HQCYQCQ1E0CwuvjXdZXUdtncErrLCUb3CE6iHkH6eKJuH0Ygh1dFXrfZhQt1rVXJ7AGpBdtuLo6DY293kI5Y7ONjQ1y-ndVInSL4yB0RqYw8pcjCp3dtkSScFmosJhWqc1FLOZbwQkcQRh5qOkmxnFA4gx0ll6Ifjz4GyXrrpedYv6LxIC3lRnp0HJQ43RnNVAyFnupkmWhrrKWkGOAaaQsJ8vobiBrLQK_rHncAvrRTK-mxekG2Kpa9Kp-APRsjUVd7s0mHHBgHiKjQix6JSosbDuARYgzcoTsMDw2WZo4knP7YaRW4ufK0EEN_iiziAiqq0GAsIouRbIKLo/file [following]\n",
            "--2021-06-18 22:09:41--  https://ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com/cd/0/inline2/BQq3yREqIgnh8ucBpYkbWs2z3fVbPo1bYQsFnVx9n9qswuY046HQCYQCQ1E0CwuvjXdZXUdtncErrLCUb3CE6iHkH6eKJuH0Ygh1dFXrfZhQt1rVXJ7AGpBdtuLo6DY293kI5Y7ONjQ1y-ndVInSL4yB0RqYw8pcjCp3dtkSScFmosJhWqc1FLOZbwQkcQRh5qOkmxnFA4gx0ll6Ifjz4GyXrrpedYv6LxIC3lRnp0HJQ43RnNVAyFnupkmWhrrKWkGOAaaQsJ8vobiBrLQK_rHncAvrRTK-mxekG2Kpa9Kp-APRsjUVd7s0mHHBgHiKjQix6JSosbDuARYgzcoTsMDw2WZo4knP7YaRW4ufK0EEN_iiziAiqq0GAsIouRbIKLo/file\n",
            "Reusing existing connection to ucb52ff7ce7a491629a91c5e75fd.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 69155672 (66M) [application/zip]\n",
            "Saving to: ‘creditfraud.zip’\n",
            "\n",
            "creditfraud.zip     100%[===================>]  65.95M  64.1MB/s    in 1.0s    \n",
            "\n",
            "2021-06-18 22:09:43 (64.1 MB/s) - ‘creditfraud.zip’ saved [69155672/69155672]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xqM1qxSvD_b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49458b4e-5cd9-46b4-a547-59de0ded83e6"
      },
      "source": [
        "!unzip creditfraud.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  creditfraud.zip\n",
            "  inflating: creditcard.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OV8v985dDi6"
      },
      "source": [
        "##Loading libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-vN7SvXvMs5"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input, Dense"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp9PNETFd2G4"
      },
      "source": [
        "##Loading dataset in Python and taking a first look"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMVr2-hzvlID",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "5c952298-c976-4a08-dec9-b10a688451b1"
      },
      "source": [
        "dat=pd.read_csv('creditcard.csv')\n",
        "dat.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y0a-xNMeDEA"
      },
      "source": [
        "The dataset is highly unbalanced with very few fraudulent credit cards"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3TwIbGCvmz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6a60be-1994-4ddd-c888-30ed0ccbac79"
      },
      "source": [
        "dat['Class'].value_counts()/dat['Class'].count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.998273\n",
              "1    0.001727\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4KRErdPvt1A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6bd67e26-87a6-40a6-bde3-bd645b518ec4"
      },
      "source": [
        "sns.countplot(x='Class',data=dat)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1b898e4a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDJt4sXDvxzb"
      },
      "source": [
        "dat = dat.drop([ 'Time'], 1)\n",
        "dat['Amount'] = StandardScaler().fit_transform(dat['Amount'].values.reshape(-1, 1))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vTh-X3beLk_"
      },
      "source": [
        "Splitting into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1T3X-3wFv001"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(dat.drop('Class',1) , dat['Class'], test_size=0.5, random_state=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooXM9UEwv3QX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18337903-51a9-419b-d898-baa4e1449815"
      },
      "source": [
        "y_test.value_counts()/y_test.count()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.998294\n",
              "1    0.001706\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3YUftDjv5z-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fd0564-d28b-44fe-b1bf-6d5cad19cd2c"
      },
      "source": [
        "y_train.value_counts()/y_train.count()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.998251\n",
              "1    0.001749\n",
              "Name: Class, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otvOl-HcevoG"
      },
      "source": [
        "##First method: using autoencoder's regression error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPpRAl0TeQR8"
      },
      "source": [
        "For our first example we will train our autoencoder only on non fraudulent cases"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMzBdaAdv7rE"
      },
      "source": [
        "X_train_normal = X_train[y_train==0]\n",
        "X_train_fraud = X_train[y_train==1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbX1U5aheSla"
      },
      "source": [
        "Building an autoencoder with\n",
        "- an input layer with 29 neurons,\n",
        "- a hidden layer with 12 neurons,\n",
        "- an output layer with 29 neurons"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euBPgiamw2R6"
      },
      "source": [
        "input_layer = Input(shape=(29, ))\n",
        "encoded = Dense(12,activation='tanh')(input_layer)\n",
        "decoded = Dense(29,activation='sigmoid')(encoded)\n",
        "autoencoder = Model(input_layer,decoded)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY42GWDWyoxL"
      },
      "source": [
        "autoencoder.compile(optimizer='adam',loss='mean_squared_error')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC2j3eXJxM-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55a23c4f-15bf-486c-be0a-6d7ebb7ba033"
      },
      "source": [
        "autoencoder.fit(X_train_normal, X_train_normal, epochs = 100, batch_size=128,\n",
        "validation_data=(X_train_normal,X_train_normal))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1111/1111 [==============================] - 16s 3ms/step - loss: 1.1179 - val_loss: 0.8840\n",
            "Epoch 2/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.8758 - val_loss: 0.8433\n",
            "Epoch 3/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.8454 - val_loss: 0.8236\n",
            "Epoch 4/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.8218 - val_loss: 0.8118\n",
            "Epoch 5/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.8114 - val_loss: 0.8037\n",
            "Epoch 6/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7912 - val_loss: 0.7979\n",
            "Epoch 7/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7935 - val_loss: 0.7937\n",
            "Epoch 8/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7994 - val_loss: 0.7904\n",
            "Epoch 9/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7834 - val_loss: 0.7879\n",
            "Epoch 10/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7947 - val_loss: 0.7858\n",
            "Epoch 11/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7923 - val_loss: 0.7843\n",
            "Epoch 12/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7830 - val_loss: 0.7826\n",
            "Epoch 13/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7758 - val_loss: 0.7815\n",
            "Epoch 14/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7851 - val_loss: 0.7805\n",
            "Epoch 15/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7783 - val_loss: 0.7794\n",
            "Epoch 16/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7697 - val_loss: 0.7787\n",
            "Epoch 17/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7723 - val_loss: 0.7779\n",
            "Epoch 18/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7818 - val_loss: 0.7774\n",
            "Epoch 19/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7872 - val_loss: 0.7768\n",
            "Epoch 20/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7860 - val_loss: 0.7763\n",
            "Epoch 21/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7869 - val_loss: 0.7758\n",
            "Epoch 22/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7796 - val_loss: 0.7756\n",
            "Epoch 23/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7713 - val_loss: 0.7751\n",
            "Epoch 24/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7725 - val_loss: 0.7748\n",
            "Epoch 25/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7661 - val_loss: 0.7748\n",
            "Epoch 26/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7739 - val_loss: 0.7744\n",
            "Epoch 27/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7810 - val_loss: 0.7740\n",
            "Epoch 28/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7665 - val_loss: 0.7738\n",
            "Epoch 29/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7733 - val_loss: 0.7736\n",
            "Epoch 30/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7702 - val_loss: 0.7735\n",
            "Epoch 31/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7691 - val_loss: 0.7732\n",
            "Epoch 32/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7801 - val_loss: 0.7729\n",
            "Epoch 33/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.8029 - val_loss: 0.7727\n",
            "Epoch 34/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7806 - val_loss: 0.7726\n",
            "Epoch 35/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7734 - val_loss: 0.7725\n",
            "Epoch 36/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7764 - val_loss: 0.7725\n",
            "Epoch 37/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7777 - val_loss: 0.7720\n",
            "Epoch 38/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7636 - val_loss: 0.7720\n",
            "Epoch 39/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7709 - val_loss: 0.7717\n",
            "Epoch 40/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7744 - val_loss: 0.7716\n",
            "Epoch 41/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7632 - val_loss: 0.7714\n",
            "Epoch 42/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7817 - val_loss: 0.7713\n",
            "Epoch 43/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7692 - val_loss: 0.7712\n",
            "Epoch 44/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7724 - val_loss: 0.7711\n",
            "Epoch 45/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7697 - val_loss: 0.7714\n",
            "Epoch 46/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7681 - val_loss: 0.7709\n",
            "Epoch 47/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7629 - val_loss: 0.7707\n",
            "Epoch 48/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7707 - val_loss: 0.7706\n",
            "Epoch 49/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7716 - val_loss: 0.7706\n",
            "Epoch 50/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7843 - val_loss: 0.7704\n",
            "Epoch 51/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7755 - val_loss: 0.7703\n",
            "Epoch 52/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7638 - val_loss: 0.7702\n",
            "Epoch 53/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7632 - val_loss: 0.7700\n",
            "Epoch 54/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7793 - val_loss: 0.7701\n",
            "Epoch 55/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7756 - val_loss: 0.7698\n",
            "Epoch 56/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7672 - val_loss: 0.7697\n",
            "Epoch 57/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7751 - val_loss: 0.7698\n",
            "Epoch 58/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7495 - val_loss: 0.7696\n",
            "Epoch 59/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7902 - val_loss: 0.7694\n",
            "Epoch 60/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7781 - val_loss: 0.7695\n",
            "Epoch 61/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7730 - val_loss: 0.7694\n",
            "Epoch 62/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7652 - val_loss: 0.7694\n",
            "Epoch 63/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7754 - val_loss: 0.7693\n",
            "Epoch 64/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7626 - val_loss: 0.7693\n",
            "Epoch 65/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7790 - val_loss: 0.7691\n",
            "Epoch 66/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7554 - val_loss: 0.7692\n",
            "Epoch 67/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7872 - val_loss: 0.7691\n",
            "Epoch 68/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7684 - val_loss: 0.7690\n",
            "Epoch 69/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7718 - val_loss: 0.7688\n",
            "Epoch 70/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7648 - val_loss: 0.7689\n",
            "Epoch 71/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7808 - val_loss: 0.7688\n",
            "Epoch 72/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7666 - val_loss: 0.7687\n",
            "Epoch 73/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7594 - val_loss: 0.7688\n",
            "Epoch 74/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7724 - val_loss: 0.7686\n",
            "Epoch 75/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7770 - val_loss: 0.7685\n",
            "Epoch 76/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7781 - val_loss: 0.7688\n",
            "Epoch 77/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7828 - val_loss: 0.7685\n",
            "Epoch 78/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7735 - val_loss: 0.7686\n",
            "Epoch 79/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7557 - val_loss: 0.7686\n",
            "Epoch 80/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7686 - val_loss: 0.7685\n",
            "Epoch 81/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7911 - val_loss: 0.7683\n",
            "Epoch 82/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7622 - val_loss: 0.7686\n",
            "Epoch 83/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7699 - val_loss: 0.7684\n",
            "Epoch 84/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7736 - val_loss: 0.7683\n",
            "Epoch 85/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7627 - val_loss: 0.7682\n",
            "Epoch 86/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7969 - val_loss: 0.7682\n",
            "Epoch 87/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7782 - val_loss: 0.7683\n",
            "Epoch 88/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7901 - val_loss: 0.7681\n",
            "Epoch 89/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7734 - val_loss: 0.7682\n",
            "Epoch 90/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7737 - val_loss: 0.7683\n",
            "Epoch 91/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7664 - val_loss: 0.7681\n",
            "Epoch 92/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7782 - val_loss: 0.7681\n",
            "Epoch 93/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7654 - val_loss: 0.7681\n",
            "Epoch 94/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7669 - val_loss: 0.7680\n",
            "Epoch 95/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7644 - val_loss: 0.7682\n",
            "Epoch 96/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7527 - val_loss: 0.7682\n",
            "Epoch 97/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7749 - val_loss: 0.7680\n",
            "Epoch 98/100\n",
            "1111/1111 [==============================] - 3s 3ms/step - loss: 0.7711 - val_loss: 0.7680\n",
            "Epoch 99/100\n",
            "1111/1111 [==============================] - 2s 2ms/step - loss: 0.7765 - val_loss: 0.7679\n",
            "Epoch 100/100\n",
            "1111/1111 [==============================] - 3s 2ms/step - loss: 0.7641 - val_loss: 0.7679\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b89b96890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzcu7y3nxsw3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "025fceb4-2dc2-4f55-d90b-778e22404890"
      },
      "source": [
        "predictions = autoencoder.predict(X_train)\n",
        "mse = np.mean(np.power(X_train - predictions, 2), axis=1)\n",
        "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
        "                        'true_class': y_train})\n",
        "error_df.groupby('true_class').describe()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"8\" halign=\"left\">reconstruction_error</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>true_class</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>142154.0</td>\n",
              "      <td>0.767910</td>\n",
              "      <td>3.441055</td>\n",
              "      <td>0.029713</td>\n",
              "      <td>0.228817</td>\n",
              "      <td>0.393219</td>\n",
              "      <td>0.651895</td>\n",
              "      <td>317.794986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>249.0</td>\n",
              "      <td>30.677632</td>\n",
              "      <td>43.615591</td>\n",
              "      <td>0.147211</td>\n",
              "      <td>4.389968</td>\n",
              "      <td>11.196580</td>\n",
              "      <td>27.837496</td>\n",
              "      <td>280.823599</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           reconstruction_error             ...                       \n",
              "                          count       mean  ...        75%         max\n",
              "true_class                                  ...                       \n",
              "0                      142154.0   0.767910  ...   0.651895  317.794986\n",
              "1                         249.0  30.677632  ...  27.837496  280.823599\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRQepwFre9UM"
      },
      "source": [
        "As we can see above the error for non fraudulent case is lower than the error for fraudulent cases. We use a threshold of mean plus 3 sds to classify the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zAII8DQxw-B"
      },
      "source": [
        "test_predictions=autoencoder.predict(X_test)\n",
        "mse = np.mean(np.power(X_test - test_predictions, 2), axis=1)\n",
        "y_pred=[(lambda er: 1 if er>=11.078922  else 0)(er) for er in mse]"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ4V1lfb46jQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "32c17c68-bd3c-4e0d-e4c1-b3c2a622254e"
      },
      "source": [
        "conf_matrix = metrics.confusion_matrix(y_test,y_pred)\n",
        "\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(conf_matrix,annot=True,ax=ax,fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
        "ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Normal', 'Fraud']); ax.yaxis.set_ticklabels(['Normal', 'Fraud']);\n",
        "ax.set(yticks=[0, 2], \n",
        "       xticks=[0.5, 1.5])\n",
        "ax.yaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEWCAYAAACAOivfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xVdb3/8dcbUISSm5rHQBNPlMcbijfUJNNCvAXlBU2TjA6Vmv0qT2r2yJPWyS5m8jtqB+94v5RKJxDJS2qJgqggXoIfhoCYykVTUZiZz++P9R3cjHPZs5k1s2fW++ljPWbt7/qu9f1uZtyf/b2s71JEYGZmxdStoytgZmYdx0HAzKzAHATMzArMQcDMrMAcBMzMCsxBwMyswBwEbKNJ6iXpD5LekHT7RlznREn3tmXdOoKkaZLGdXQ9zMrhIFAgkr4kabaktyQtTx9Wn2qDSx8DbA1sERHHVnqRiLgxIka2QX02IOkgSSHpzgbpQ1P6g2Ve5z8l3dBSvog4LCKuq7C6Zu3KQaAgJH0X+A3wX2Qf2NsBlwGj2+DyHwP+FhE1bXCtvLwG7Cdpi5K0ccDf2qoAZfz/lHUq/oMtAEl9gfOB0yLi9xHxdkSsi4g/RMR/pDw9Jf1G0stp+42knunYQZKWSvqepFdTK+KUdOzHwI+AsamFMb7hN2ZJ26dv3D3S669IWiTpn5JelHRiSfojJeftL2lW6maaJWn/kmMPSrpA0l/Sde6VtGUz/wxrgbuA49P53YGxwI0N/q0ukbRE0puSnpB0YEofBfyg5H0+XVKPn0r6C/AOsENK+1o6frmk35Vc/+eS7pOksn+BZjlyECiG/YDNgDubyXMuMBzYHRgK7AP8sOT4vwB9gYHAeOBSSf0j4jyy1sWtEfHhiLiquYpI+hAwETgsIjYH9geeaiTfAOCPKe8WwK+BPzb4Jv8l4BTgI8CmwJnNlQ1MBk5O+4cCzwAvN8gzi+zfYABwE3C7pM0i4p4G73NoyTlfBiYAmwOLG1zve8CuKcAdSPZvNy68XotVCQeBYtgCeL2F7poTgfMj4tWIeA34MdmHW7116fi6iJgKvAV8ssL61AG7SOoVEcsjYn4jeY4AFkTE9RFRExE3A88DR5XkuSYi/hYRa4DbyD68mxQRfwUGSPokWTCY3EieGyJiRSrzIqAnLb/PayNifjpnXYPrvUP27/hr4AbgWxGxtIXrmbUbB4FiWAFsWd8d04SPsuG32MUpbf01GgSRd4APt7YiEfE2WTfMN4Dlkv4oaccy6lNfp4Elr1+poD7XA6cDn6GRlpGkMyU9l7qgVpO1fprrZgJY0tzBiHgMWASILFiZVQ0HgWJ4FHgPGNNMnpfJBnjrbccHu0rK9TbQu+T1v5QejIjpEfE5YBuyb/dXlFGf+jotq7BO9a4HTgWmpm/p66Xumu8DxwH9I6If8AbZhzdAU104zXbtSDqNrEXxcrq+WdVwECiAiHiDbPD2UkljJPWWtImkwyT9ImW7GfihpK3SAOuPyLovKvEUMELSdmlQ+pz6A5K2ljQ6jQ28R9atVNfINaYCn0jTWntIGgvsBPxvhXUCICJeBD5NNgbS0OZADdlMoh6SfgT0KTn+D2D71swAkvQJ4CfASWTdQt+X1Gy3lVl7chAoiNS//V2ywd7XyLowTiebMQPZB9VsYC4wD5iT0iopawZwa7rWE2z4wd0t1eNlYCXZB/I3G7nGCuBIsoHVFWTfoI+MiNcrqVODaz8SEY21cqYD95BNG10MvMuGXT31N8KtkDSnpXJS99sNwM8j4umIWEA2w+j6+plXZh1NnqRgZlZcbgmYmRWYg4CZWYE5CJiZFZiDgJlZG5N0dVpi5ZlGjn0vLaOyZXotSRMlLZQ0V9KwkrzjJC1I27iS9D0lzUvnTKxfhkTSAEkzUv4Zkvq3WNdqHRhe9/qi6qyYdajeHz2wo6tgVWjd2mUbvRZTaz5zNtlyh2bLkzSCbPrz5IjYpSR9W+BKYEdgz4h4XdLhwLeAw4F9gUsiYt+0dMpsYC+ye1GeSOeskvQ4cAbwGNl06okRMS1N+V4ZERdKOpvsfpezmqurWwJmZm0sIh4imwLd0MVk051LA85osmARETET6CdpG7L1rWZExMqIWAXMAEalY30iYmZag2oy798IOhqoX8b8Opq/QRSA5pYRMDMrjrraXC8vaTSwLCKebrCI7EA2vB9laUprLn1pI+kAW0fE8rT/Ctmy8c1yEDAzA6gt/3EYkiaQrRxbb1JETGomf2+yGwXb/KFJTYmIkNRiF5eDgJkZENHY6iVN5Y1JQJMf+o34V2AwUN8KGATMkbQP2XpY25bkHZTSlgEHNUh/MKUPaiQ/wD8kbRMRy1O30astVcxjAmZmAHV15W+tFBHzIuIjEbF9RGxP1oUzLCJeAaYAJ6dZQsOBN1KXznRgpKT+aZbPSGB6OvampOFpVtDJwN2pqClkT8wj/bybFrglYGYG0IqWQEsk3Uz2LX5LSUuB85p54NJUsplBC8mWRD8FICJWSrqA7EFHkD3Po36w+VTgWqAXMC1tABcCt0kaT7b+1XEt1tVTRK0z8RRRa0xbTBFdu3hO2Z85m35sWJd5PKhbAmZm0KYtgc7EQcDMDIhWzA7qShwEzMygogHfrsBBwMwM3B1kZlZoOd8xXK0cBMzMwC0BM7NC88CwmVmBeWDYzKy4IjwmYGZWXB4TMDMrMHcHmZkVmFsCZmYFVruuo2vQIRwEzMzA3UFmZoXm7iAzswJzS8DMrMAcBMzMiis8MGxmVmAeEzAzKzB3B5mZFZhbAmZmBVbQlkC3jq6AmVlViLrytxZIulrSq5KeKUn7paTnJc2VdKekfiXHzpG0UNILkg4tSR+V0hZKOrskfbCkx1L6rZI2Tek90+uF6fj2LdXVQcDMDKCmpvytZdcCoxqkzQB2iYjdgL8B5wBI2gk4Htg5nXOZpO6SugOXAocBOwEnpLwAPwcujoiPA6uA8Sl9PLAqpV+c8jXLQcDMDNq0JRARDwErG6TdGxH1EWQmMCjtjwZuiYj3IuJFYCGwT9oWRsSiiFgL3AKMliTgYOCOdP51wJiSa12X9u8ADkn5m+QgYGYG2ZhAmZukCZJml2wTWlnaV4FpaX8gsKTk2NKU1lT6FsDqkoBSn77BtdLxN1L+Jnlg2MwMWjU7KCImAZMqKUbSuUANcGMl57c1BwEzM2iX2UGSvgIcCRwSEZGSlwHblmQblNJoIn0F0E9Sj/RtvzR//bWWSuoB9E35m+TuIDMzaNMxgcZIGgV8H/h8RLxTcmgKcHya2TMYGAI8DswChqSZQJuSDR5PScHjAeCYdP444O6Sa41L+8cA95cEm0a5JWBmBuXO+imLpJuBg4AtJS0FziObDdQTmJHGamdGxDciYr6k24BnybqJTov01HtJpwPTge7A1RExPxVxFnCLpJ8ATwJXpfSrgOslLSQbmD6+xbq2ECQ6zLrXF1VnxaxD9f7ogR1dBatC69Yua3YGTDnW3Prjsj9zeo09b6PLqxZuCZiZQWHvGHYQMDMDBwEzs0LzAnJmZgVWW9vRNegQDgJmZuDuIDOzQnMQMDMrMI8JmJkVV9QV89YkBwEzM3B3kJlZoXl2kJlZgbklYGZWYAUNAl5KOkc//K9fM+KI4xlz0jc+cOzam3/HLgccxqrVbwCwaPESTpzwHfY46CiuuemO9fnee28tx3/t23xx3KmMPvHr/PeV168/9tgTT3HsKacz5qRv8IMLfkVNzYbN2XnPvcDQEUdw7wMP5/QOLS+f+MS/MnvWveu3Fa8/zxnf+hoAp516CvPm/Zmnnrqfn/3sXABOOOELG+R/790lDB26c0e+hc4novytC3FLIEdjDv8cXzr68/zggl9tkL78H6/x18fnsM3WH1mf1rfP5pz9nW9w/0OPbpB300034eqJF9K7dy/W1dRw8jfP5MDhe7HrTp/kBz+5iKsu+RnbbzeI/75iMndP+xNHH3UoALW1tVx82TXsv/ew/N+otbm//e3/sdfeIwHo1q0bi//+BHfdPY1Pf3p/jjrqUPbc83OsXbuWrbbKnhx48813cvPNdwKwyy47csftV/H00/ObvL41wi0Ba2t77b4rffts/oH0X0z8H7576nhKH/+8Rf9+7Ppvn6RHjw3jsiR69+4FQE1NDTU1NUhi9RtvskmPHmy/Xfas6v32HsafHnxk/Xk33TGFzx10AAP698vhnVl7OvjgT7Fo0WJeemkZX//6yfzil5eydu1aAF577YMPjRo7dgy33T6lvavZ+dVF+VsXkksQkDSsuS2PMjuL+x9+lI9stSU7Dtmh7HNqa2s5etxpjDjyBPbbew9223lH+vfrS21tHc889zcA7n3wEV559XUA/vHa69z30F8Z+4UjcnkP1r7GHjeaW2+9C4BPDNmBT31qH/7yyB+47093sNeeQz+Q/9hjjlqf31qhtrb8rQvJqzvoomaOBXBwYwckTQAmAFx20U/42skn5FC1jrPm3Xe5YvKtTLr4p606r3v37vzuukt5859v8e1zLmDBor8zZIft+eX5Z/OLiZNYu24d++8zjG7dspj+80v+h+9886vrX1vntckmm3DkkSM594c/A6B7j+4M6N+PAz51FHvvtTs33fRbPvHJ/dbn32fvPVizZg3z57/QUVXutKKg3UG5BIGI+EyF500CJkHXfLLYkmXLWfbyKxw97lQg+8Z+7Fe/xS1X/IYttxjQ4vl9Nv8w+wzbjUdmzmbIDtuz+y7/xuTLs/GGvzz2BIuXZM+anv/8Av7jvAsBWPXGmzz86Cy6d+/OISP2z+mdWV5GjfoMTz45j1dTK2/Z0uXcedc0AGbNfoq6ujq23HIAr7++EoDjjhvNLbfe3eT1rBldrJunXLkPDEvaBdgJ2Kw+LSIm511uNfrEvw7moT/esv71yKPHcetVE+nfr2+T56xctZoePXrQZ/MP8+577/HorCf56knHArBi1Wq26N+PtWvXcvWNtzNhXPY40el3XLv+/HN/chGfPmAfB4BOauzYMRt07UyZMp2DDtqfP//5rwwZsgObbrrp+gAgiWOOOZLPHPzFjqpu5+a1g9qepPPIHra8EzAVOAx4BChEEPiP8y5k1pNzWb36TQ4ZcxKnjv/y+tk7Db2+YiVjx5/BW2+/Q7du3bjhtru4+8b/4bUVqzj3J7+itq6OqAsOPfhADjpgXwCuufEO/vzXx4m6OsZ+4Qj23XP39nx7lrPevXvx2UNGcOqpZ61Pu+baW7jyiot48sn7WLd2HV8d/3/WHzvwwOEsXbqcF198qSOq2/kVtCWQ64PmJc0DhgJPRsRQSVsDN0TE51o6tyt2B9nG84PmrTFt8aD5t390fNmfOR86/xY/aL5MayKiTlKNpD7Aq8C2OZdpZtZ6Be0Oynv6yGxJ/YArgCeAOcCjzZ9iZtYB2vA+AUlXS3pV0jMlaQMkzZC0IP3sn9IlaaKkhZLmlk6jlzQu5V8gaVxJ+p6S5qVzJkrZXUdNldGcXINARJwaEasj4rfA54BxEXFKnmWamVUi6urK3spwLTCqQdrZwH0RMQS4L72GbKx0SNomAJdD9oEOnAfsC+wDnFfyoX458O8l541qoYwm5T6RXNJukj4PDAM+LslTF8ys+rRhSyAiHgJWNkgeDVyX9q8DxpSkT47MTKCfpG2AQ4EZEbEyIlYBM4BR6VifiJgZ2aDu5AbXaqyMJuU9O+hqYDdgPlAfPgP4fZ7lmpm1WitmB5Xe2JpMSvc5NWfriFie9l8Btk77A4ElJfmWprTm0pc2kt5cGU3Ke2B4eETslHMZZmYbrxXLQZTe2FqJiAhJuc6ALLeMvLuDHpXkIGBmVS/qouytQv9IXTmkn6+m9GVsOGtyUEprLn1QI+nNldGkvIPAZLJA8EIa9Z4naW7OZZqZtV7+q4hOAepn+IwD7i5JPznNEhoOvJG6dKYDIyX1TwPCI4Hp6dibkoanWUEnN7hWY2U0Ke/uoKuALwPzeH9MwMys+rThAnKSbiZbLWFLSUvJZvlcCNwmaTywGDguZZ8KHA4sBN4BTgGIiJWSLgBmpXznR0T9YPOpZDOQegHT0kYzZTRd15zvGH40IvZrOecH+Y5ha4zvGLbGtMUdw/889bCyP3M2v2ya7xgu05OSbgL+ALxXnxgRnh1kZtWloGsH5R0EepF9+I8sSfMUUTOrOlFbzB7r3IKApO7Aiog4M68yzMzajFsCbSsiaiUdkNf1zcza0kZM/ezU8u4OekrSFOB24O36RI8JmFnVcRDIxWbACjZ8prDHBMys+hRzSCDfIOAVQ82ss4iaYkaBXO8YljRI0p1pXe1XJf1O0qCWzzQza2d1rdi6kLyXjbiG7Dbmj6btDynNzKyqtMPaQVUp7yCwVURcExE1absW2CrnMs3MWs8tgVyskHSSpO5pO4lsoNjMrKq4JZCPr5ItYPQKsBw4hrQ4kplZVSloSyDv2UGLgc/nWYaZWVuImo6uQcfIJQhI+lEzhyMiLsijXDOzSkUX+4ZfrlZ1B6WHG+xWRta3G9kAxgNntaqGZmbtwd1BjZP0IFmXTg/gCeBVSX+JiO82dU5EXFRy/ubAt8nGAm4BLmrqPDOzjuKWQNP6RsSbwBeByRGxL/DZlk6SNEDST4C5ZAFkWEScFREtPvPSzKy9RV35W1dSzphAj/TA4uOAc8u5qKRfkgWNScCuEfFW5VU0M8tf1HaZh4W1SjktgfPJHni8MCJmSdoBWNDCOd8ju0P4h8DLkt5M2z8lvblxVTYza3tuCTQhIm4nWwq6/vUi4OgWzsn7/gMzszYVdcVsCTQZBCT9X7JlnxsVEWfkUiMzsw7Q1b7hl6u5lsDsdquFmVkHi3BLYAMRcV3pa0m9I+Kd/KtkZtb+2rIlIOk7wNfIelPmkU2R34ZsmvwWZNPtvxwRayX1BCYDe5KtrTY2Iv6ernMO2f1VtcAZETE9pY8CLgG6A1dGxIWV1rXFvntJ+0l6Fng+vR4q6bJKCzQzq0Z1tSp7a46kgcAZwF4RsQvZB/XxwM+BiyPi48Aqsg930s9VKf3ilA9JO6XzdgZGAZfVL8YJXAocBuwEnJDyVqScAdzfAIeSVv+MiKeBEZUWaGZWjaJOZW9l6AH0ktQD6E22gObBwB3p+HXAmLQ/Or0mHT9EklL6LRHxXkS8CCwE9knbwohYFBFryVoXoyt932XN4omIJQ2Saist0MysGrUmCEiaIGl2yTZh/XUilgG/Al4i+/B/g6z7Z3XE+mXqlgID0/5AYEk6tybl36I0vcE5TaVXpJybxZZI2h8ISZuQLQHxXKUFmplVo2jFYwIiYhLZzbAfIKk/2TfzwcBqsin2oza+hvkoJwh8g2wAYiDwMtmNY6flWSkzs/bWhvcJfBZ4MSJeA5D0e+AAoJ+kHunb/iBgWcq/DNgWWJq6j/qSdb/Xp9crPaep9FZrsTsoIl6PiBMjYuuI2CoiTooIPx3MzLqUCJW9teAlYLik3qlv/xDgWeABsgdrAYwD7k77U9Jr0vH7IyJS+vGSekoaDAwBHgdmAUMkDZa0Kdng8ZRK33c5q4juQNYSGE423elR4DvpzmEzsy6hto3WDoqIxyTdAcwBaoAnybqO/gjckhbWfBK4Kp1yFXC9pIXASrIPdSJivqTbyAJIDXBaRNQCSDqdrFemO3B1RMyvtL6KFjrCJM0km450c0o6HvhWWk00N+teX9S1HuRpbaL3Rw/s6CpYFVq3dtlGf4K/sONhZX/mfPL5aV3mzrJyZgf1jojrI6ImbTcAm+VdMTOz9tTGU0Q7jebWDhqQdqdJOptsLmoAY4Gp7VA3M7N205rZQV1Jc2MCT5B96NeHva+XHAvgnLwqZWbW3rraN/xyNbd20OD2rIiZWUeqrSvmCvjl3CeApF3I1qhYPxYQEZPzqpSZWXtzd1ATJJ0HHEQWBKaSLVr0CNmqd2ZmXUJdQZeSLqf9cwzZzQ6vRMQpwFCyO9rMzLqMNrxZrFMppztoTUTUSaqR1Ad4lQ1vWTYz6/TcHdS02ZL6AVeQzRh6i+yu4Vz18k1BZtaOitodVM6D5k9Nu7+VdA/QJyLm5lstM7P25dlBDUga1tyxiJiTT5XMzNpfQXuDmm0JXNTMsSB7So6ZWZfg7qAGIuIz7VkRM7OO1NVm/ZSrrJvFzMy6urqOrkAHcRAwMwMCtwTMzAqrpqDdQS3OiVLmJEk/Sq+3k7RP/lUzM2s/gcreupJyJsZeBuwHnJBe/5PsSWNmZl1GXSu2rqSc7qB9I2KYpCcBImJVerixmVmX0dW+4ZernCCwTlJ30r0Ukrai6wVDMyu4on6olRMEJgJ3Ah+R9FOyVUV/mGutzMzaWW1BWwItjglExI3A94GfAcuBMRFxe94VMzNrT3Uqf2uJpH6S7pD0vKTnJO0naYCkGZIWpJ/9U15JmihpoaS5pUv2SBqX8i+QNK4kfU9J89I5EyVVHMHKmR20HfAO8AdgCvB2SjMz6zLqUNlbGS4B7omIHcmewfIccDZwX0QMAe5LryF7UNeQtE0ALgeQNAA4D9gX2Ac4rz5wpDz/XnLeqErfdzndQX/k/QfObwYMBl4Adq60UDOzatNWC8hJ6guMAL4CEBFrgbWSRpM9pRHgOuBB4CxgNDA5IgKYmVoR26S8MyJiZbruDGCUpAfJVnOemdInA2OAaZXUt5ylpHdt8AaHAac2kd3MrFNqw4HhwcBrwDWShpI9h+XbwNYRsTzleQXYOu0PBJaUnL80pTWXvrSR9Iq0egHttIT0vpUWaGZWjeqksjdJEyTNLtkmlFyqBzAMuDwi9gDe5v2uHwDSt/6qWL26nAfNf7fkZTeyN/dybjUyM+sAta3IGxGTgElNHF4KLI2Ix9LrO8iCwD8kbRMRy1N3z6vp+DI2fGTvoJS2jPe7j+rTH0zpgxrJX5FyWgKbl2w9ycYIRldaoJlZNWqr2UER8QqwRNInU9IhwLNkE2vqZ/iMA+5O+1OAk9MsoeHAG6nbaDowUlL/NCA8Epiejr0paXiaFXRyybVardmWQLpJbPOIOLPSAszMOoMyZ/2U61vAjWl1hUXAKWRfum+TNB5YDByX8k4FDgcWks3EPAUgIlZKugCYlfKdXz9ITDYuey3Qi2xAuKJBYQBlXVONHJB6RESNpEcjYr9KC6hUj00HVkV/mZlVv5q1yzb6E/yGj55U9mfOSS/f0GXuLGuuJfA4Wf//U5KmALeTDXAAEBG/z7luZmbtppybwLqicu4T2AxYQfZM4fr7BQJwEDCzLsNrB33QR9LMoGd4/8O/nrtqzKxLqXVL4AO6Ax+GRkdLHATMrEtxS+CDlkfE+e1WEzOzDuQg8EEFbRyZWREV9BHDzQaBQ9qtFmZmHcwtgQZKbkowM+vyWrNsRFdSzhRRM7Muz/cJmJkVmLuDzMwKzEHAzKzAinrzk4OAmRkeEzAzKzTPDjIzK7C6gnYIOQiYmeGBYTOzQitmO8BBwMwMcEvAzKzQalTMtoCDgJkZ7g4yMys0dweZmRVYUaeIduvoCpiZVYNoxVYOSd0lPSnpf9PrwZIek7RQ0q2SNk3pPdPrhen49iXXOCelvyDp0JL0USltoaSzN+Z9OwiYmZF1B5W7lenbwHMlr38OXBwRHwdWAeNT+nhgVUq/OOVD0k7A8cDOwCjgshRYugOXAocBOwEnpLwVcRAwMwNqibK3lkgaBBwBXJleCzgYuCNluQ4Yk/ZHp9ek44ek/KOBWyLivYh4EVgI7JO2hRGxKCLWArekvBVxEDAzo3UtAUkTJM0u2SY0uNxvgO/zfsNhC2B1RNSk10uBgWl/ILAEIB1/I+Vfn97gnKbSK+KBYTMzIFoxMBwRk4BJjR2TdCTwakQ8IemgtqldfhwEzMxo0ymiBwCfl3Q4sBnQB7gE6CepR/q2PwhYlvIvA7YFlkrqAfQFVpSk1ys9p6n0VnN3UBW4YtJFvLz0aZ568r71aT//2Q95Zt6fmfPEDO64/Ur69u2z/tiuu/4bjzw0haefup8n5/yJnj17dkS1LWeN/V0cffSRPP3U/ax9dwl7DtttffoJJ3yB2bPuXb+tfXcJQ4fu3BHV7rTqiLK35kTEORExKCK2JxvYvT8iTgQeAI5J2cYBd6f9Kek16fj9EREp/fg0e2gwMAR4HJgFDEmzjTZNZUyp9H07CFSByZNv44gjT9wg7U/3PcTQ3Q9m2J6fY8GCRZx91ukAdO/eneuuncipp5/N0N0P5pDPHsu6des6otqWs8b+LubPf55jj/t3Hn545gbpN998J3vtPZK99h7JV045gxdffImnn57fntXt9Np6imgjzgK+K2khWZ//VSn9KmCLlP5d4GyAiJgP3AY8C9wDnBYRtaklcTownWz20W0pb0XcHVQFHn7kMT72sUEbpM3400Pr92c+Noejv3gEACM/92nmzXuOuXOfBWDlylXtV1FrV439XTz//MIWzzt+7Bhuu73iL4aFVZPDzWIR8SDwYNpfRDazp2Ged4Fjmzj/p8BPG0mfCkxtizrm0hKQNKC5LY8yu7JTvnI890x/AIAhQ3YgAqb+7408/tg9nPm9b3Zw7azaHHvMUdxy610dXY1OJ1rxX1eSV0vgCbJWk4DtyG6MENAPeAkY3NhJaZrVBAB170u3bh/KqXqdxzlnn0FNTQ033fR7AHr06M4B++/N8P0P55131jBj+m3MmTOP+x94pINratVgn7334J01a5g//4WOrkqnU9S1g3JpCUTE4IjYAfgTcFREbBkRWwBHAvc2c96kiNgrIvZyAICTv3wcRxz+Wb588unr05YuW87DjzzGihWrWLPmXabdcz977LFLB9bSqsnY40Zz6613t5zRPqCoLYG8B4aHp74rACJiGrB/zmV2CYeOPIgzz/wmY774FdaseXd9+r33/plddtmRXr02o3v37ow4cDjPPbegA2tq1UISxxxzJLfe5iBQiRyWjegU8h4YflnSD4Eb0usTgZdzLrPTueH6S/n0iP3YcssB/H3RbH58/q846/un07NnT+6ZdgsAjz02h9NOP5vVq9/gN5dMYuajU4kI7rnnfqZOu6+FEqwzauzvYuWq1Vxy8Yg4BLkAAApoSURBVE/YaqsBTLl7Mk8/PZ/D0wyiEQcOZ+nS5bz44ksdXPPOqTa61jf8cilyfONpEPg8YERKegj4cUSsbOncHpsOLOZvxMxarWbtMm3sNb70sS+U/Zlz0+I7N7q8apFrSyB92H87zzLMzNpCV+vrL1euQUDSAzRyb0VEHJxnuWZmrdXV+vrLlfeYwJkl+5sBRwM1TeQ1M+swRX2yWN7dQU80SPqLpMfzLNPMrBLuDspBg7uDuwF7kq2QZ2ZWVYo6Oyjv7qDSO4drgBd5/5FqZmZVw91BOYiIRpeHMDOrNh4YzomkXcgehrxZfVpETM67XDOz1vCYQA4knQccRBYEpgKHAY8ADgJmVlWK2h2U99pBxwCHAK9ExCnAUDwwbGZVKCLK3rqSvLuD1kREnaQaSX2AV9nw2ZhmZlWhtqAtgbyDwGxJ/YAryGYKvQU8mnOZZmatVtTuoNyCgCQBP4uI1cBvJd0D9ImIuXmVaWZWqa7WzVOu3IJARISkqcCu6fXf8yrLzGxjFbUlkPfA8BxJe+dchpnZRivqk8XyHhPYFzhJ0t+Bt8nuHI6I2C3ncs3MWqWoy0bk0hKQtF3aPRTYATgYOIrsGcNH5VGmmdnGqCPK3pojaVtJD0h6VtJ8Sd9O6QMkzZC0IP3sn9IlaaKkhZLmShpWcq1xKf8CSeNK0veUNC+dMzGNwVYkr+6guwAiYjHw64hYXLrlVKaZWcXaKgiQrZP2vYjYCRgOnCZpJ+Bs4L6IGALcl15DdhPtkLRNAC6HDZ7MuC+wD3BefeBIef695LxRlb7vvIJAaVTaIacyzMzaTFvdLBYRyyNiTtr/J/AcMBAYDVyXsl0HjEn7o4HJkZkJ9JO0DVlPyoyIWBkRq4AZwKh0rE9EzIysMpNLrtVqeQWBaGLfzKwqtaYlIGmCpNkl24TGrilpe2AP4DFg64hYng69Amyd9gcCS0pOW5rSmktf2kh6RfIaGB4q6U2yFkGvtA/vDwz3yalcM7OKtGbWT0RMAiY1l0fSh4HfAf8nIt4s7bZPU+ir4gtyLkEgIrrncV0zs7zURtstJi1pE7IAcGNE/D4l/0PSNhGxPHXpvJrSl7HhcjqDUtoysgU4S9MfTOmDGslfkbzvEzAz6xTaakwgzdS5CnguIn5dcmgKUD/DZxxwd0n6yWmW0HDgjdRtNB0YKal/GhAeCUxPx96UNDyVdXLJtVot9+cJmJl1Bm14x/ABwJeBeZKeSmk/AC4EbpM0HlgMHJeOTQUOBxYC7wCnAETESkkXALNSvvMjYmXaPxW4FugFTEtbRVSt62X02HRgdVbMzKpOzdplFc+Tr7fbv+xX9mfO3Fce3ejyqoVbAmZmQF2VfiHOm4OAmRl+vKSZWaG15eygzsRBwMwMdweZmRWau4PMzArMLQEzswJzS8DMrMBqo7ajq9AhHATMzPCD5s3MCq2oD5p3EDAzwy0BM7NC8+wgM7MC8+wgM7MC87IRZmYF5jEBM7MC85iAmVmBuSVgZlZgvk/AzKzA3BIwMyswzw4yMyswDwybmRWYu4PMzArMdwybmRWYWwJmZgVW1DEBFTX6dSaSJkTEpI6uh1UX/11YW+jW0RWwskzo6ApYVfLfhW00BwEzswJzEDAzKzAHgc7B/b7WGP9d2EbzwLCZWYG5JWBmVmAOAmZmBeYgkDNJIemiktdnSvrPdq7Dg5L2as8yrXUk1Up6qmTbPocy/i5py7a+rnVuvmM4f+8BX5T0s4h4vbUnS+oRETU51Muqy5qI2L2xA5JENn5XzLWOLVduCeSvhmwWx3caHpC0vaT7Jc2VdJ+k7VL6tZJ+K+kx4Bfp9eWSZkpaJOkgSVdLek7StSXXu1zSbEnzJf24vd6gtb30t/GCpMnAM8C2Tf1+S7/hS9pL0oNpfwtJ96b8VwLqiPdi1c1BoH1cCpwoqW+D9P8LXBcRuwE3AhNLjg0C9o+I76bX/YH9yILJFOBiYGdgV0n13yDPjYi9gN2AT0vaLZd3Y3noVdIVdGdKGwJcFhE7R8RiWv/7PQ94JCJ2Bu4Etsut9tZpOQi0g4h4E5gMnNHg0H7ATWn/euBTJcduj4jaktd/iGw+7zzgHxExL3UPzAe2T3mOkzQHeJIsQOzUpm/E8rQmInZP2xdS2uKImFmSp7W/3xHADQAR8UdgVVtX2jo/jwm0n98Ac4Brysz/doPX76WfdSX79a97SBoMnAnsHRGrUjfRZpVX16rA+r+BFn6/Nbz/hc6/c2sVtwTaSUSsBG4Dxpck/xU4Pu2fCDy8EUX0IfvQeEPS1sBhG3Etqz7N/X7/DuyZ9o8uSX8I+BKApMPIuhTNNuAg0L4uAkqn6H0LOEXSXODLwLcrvXBEPE3WTfA8WRfTXzainlZlWvj9/hi4RNJsoLZB+ghJ84EvAi+1U3WtE/GyEWZmBeaWgJlZgTkImJkVmIOAmVmBOQiYmRWYg4CZWYE5CNgHlKxo+Yyk2yX13ohrXSvpmLR/paQm73JNayLtX0EZja6OWc6qmZLeamVZ/ynpzNbW0axaOQhYY+qXMNgFWAt8o/SgpIruNI+Ir0XEs81kOQhodRAws8o5CFhLHgY+nr6lPyxpCvCspO6SfilpVloF9euQLXss6b/TCph/Aj5Sf6HS5xpIGiVpjqSn0wqq25MFm++kVsiBkraS9LtUxixJB6RzW706pqS7JD2RzpnQ4NjFKf0+SVultH+VdE8652FJOzZyzTMkPZve/y2V/fOadSyvHWRNSt/4DwPuSUnDgF0i4sX0QfpGROwtqSfwF0n3AnsAnyRb3Gxr4Fng6gbX3Qq4AhiRrjUgIlZK+i3wVkT8KuW7Cbg4Ih5Jy2xPB/6N91fHPF/SEWy4FEdTvprK6AXMkvS7iFgBfAiYHRHfkfSjdO3TyZb//kZELJC0L3AZcHCDa54NDI6I9yT1K+sf1azKOAhYY3pJeirtPwxcRdZN83hEvJjSRwK71ff3A33Jlj4eAdycVkB9WdL9jVx/OPBQ/bXSukqN+Sywk7T+i34fSR9OZXwxnftHSeWsjnmGpPrVObdNdV1BtgDfrSn9BuD3qYz9gdtLyu7ZyDXnAjdKugu4q4w6mFUdBwFrzAeecpU+DEtXNhXwrYiY3iDf4W1Yj27A8Ih4t5G6lE3SQWQBZb+IeCc9dKWp1TYjlbu6qSd9lTiCLCAdBZwraVc/Bc46G48JWKWmA9+UtAmApE9I+hDZypVj05jBNsBnGjl3JtnCZoPTuQNS+j+BzUvy3Uu2yB4pX/2HcmtXx+wLrEoBYEeylki9bkB9a+ZLZN1MbwIvSjo2lSFJQ0svKKkbsG1EPACclcr4cAv1MKs6DgJWqSvJ+vvnSHoG+B+yluWdwIJ0bDLwaMMTI+I1YAJZ18vTvN8d8wfgC/UDw2QP4dkrDbw+y/uzlFq7OuY9ZM9ceA64kCwI1Xsb2Ce9h4OB81P6icD4VL/5wOgG1+wO3CBpHtnqnhMjYnUL9TCrOl5F1MyswNwSMDMrMAcBM7MCcxAwMyswBwEzswJzEDAzKzAHATOzAnMQMDMrsP8PCwVCmGc2We8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh2xw3tcfng9"
      },
      "source": [
        "##Second method: using encoder part of autoencoder and k-NN\n",
        "\n",
        "We train using all cases (fraud/non-fraud)in train dataset and use the result to map the instances into a 12-dimensional space. The mapped cases are fed to k-NN for classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7SnYf1KFVm9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c844304e-230d-4385-ffeb-8f8640250eca"
      },
      "source": [
        "input_layer_all = Input(shape=(29, ))\n",
        "encoded_all = Dense(12,activation='tanh')(input_layer_all)\n",
        "decoded_all = Dense(29,activation='sigmoid')(encoded_all)\n",
        "autoencoder_all = Model(input_layer_all,decoded_all)\n",
        "autoencoder_all.compile(optimizer='adam',loss='mean_squared_error')\n",
        "autoencoder_all.fit(X_train, X_train, epochs = 100, batch_size=128,\n",
        "validation_data=(X_train,X_train))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1113/1113 [==============================] - 4s 3ms/step - loss: 1.1684 - val_loss: 0.9398\n",
            "Epoch 2/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.9049 - val_loss: 0.8965\n",
            "Epoch 3/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8966 - val_loss: 0.8765\n",
            "Epoch 4/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8692 - val_loss: 0.8633\n",
            "Epoch 5/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8502 - val_loss: 0.8539\n",
            "Epoch 6/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8575 - val_loss: 0.8468\n",
            "Epoch 7/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8562 - val_loss: 0.8424\n",
            "Epoch 8/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8396 - val_loss: 0.8387\n",
            "Epoch 9/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8352 - val_loss: 0.8360\n",
            "Epoch 10/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8338 - val_loss: 0.8339\n",
            "Epoch 11/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8563 - val_loss: 0.8322\n",
            "Epoch 12/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8232 - val_loss: 0.8308\n",
            "Epoch 13/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8276 - val_loss: 0.8297\n",
            "Epoch 14/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8289 - val_loss: 0.8286\n",
            "Epoch 15/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8245 - val_loss: 0.8279\n",
            "Epoch 16/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8324 - val_loss: 0.8271\n",
            "Epoch 17/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8292 - val_loss: 0.8267\n",
            "Epoch 18/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8173 - val_loss: 0.8262\n",
            "Epoch 19/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8300 - val_loss: 0.8256\n",
            "Epoch 20/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8279 - val_loss: 0.8252\n",
            "Epoch 21/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8279 - val_loss: 0.8249\n",
            "Epoch 22/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8359 - val_loss: 0.8244\n",
            "Epoch 23/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8108 - val_loss: 0.8242\n",
            "Epoch 24/100\n",
            "1113/1113 [==============================] - 4s 3ms/step - loss: 0.8429 - val_loss: 0.8240\n",
            "Epoch 25/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8340 - val_loss: 0.8235\n",
            "Epoch 26/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8060 - val_loss: 0.8235\n",
            "Epoch 27/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.7995 - val_loss: 0.8233\n",
            "Epoch 28/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.7945 - val_loss: 0.8231\n",
            "Epoch 29/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8001 - val_loss: 0.8233\n",
            "Epoch 30/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8393 - val_loss: 0.8226\n",
            "Epoch 31/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8214 - val_loss: 0.8225\n",
            "Epoch 32/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8194 - val_loss: 0.8223\n",
            "Epoch 33/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8100 - val_loss: 0.8221\n",
            "Epoch 34/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8296 - val_loss: 0.8222\n",
            "Epoch 35/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8337 - val_loss: 0.8219\n",
            "Epoch 36/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8288 - val_loss: 0.8218\n",
            "Epoch 37/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8211 - val_loss: 0.8224\n",
            "Epoch 38/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8150 - val_loss: 0.8214\n",
            "Epoch 39/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8174 - val_loss: 0.8215\n",
            "Epoch 40/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8090 - val_loss: 0.8213\n",
            "Epoch 41/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8188 - val_loss: 0.8210\n",
            "Epoch 42/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8024 - val_loss: 0.8208\n",
            "Epoch 43/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8330 - val_loss: 0.8208\n",
            "Epoch 44/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8377 - val_loss: 0.8205\n",
            "Epoch 45/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8139 - val_loss: 0.8203\n",
            "Epoch 46/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8274 - val_loss: 0.8203\n",
            "Epoch 47/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8134 - val_loss: 0.8200\n",
            "Epoch 48/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8161 - val_loss: 0.8198\n",
            "Epoch 49/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8372 - val_loss: 0.8197\n",
            "Epoch 50/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8263 - val_loss: 0.8196\n",
            "Epoch 51/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.7982 - val_loss: 0.8201\n",
            "Epoch 52/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8018 - val_loss: 0.8192\n",
            "Epoch 53/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8417 - val_loss: 0.8195\n",
            "Epoch 54/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8170 - val_loss: 0.8196\n",
            "Epoch 55/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8120 - val_loss: 0.8195\n",
            "Epoch 56/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8227 - val_loss: 0.8195\n",
            "Epoch 57/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8031 - val_loss: 0.8189\n",
            "Epoch 58/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8214 - val_loss: 0.8188\n",
            "Epoch 59/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8315 - val_loss: 0.8187\n",
            "Epoch 60/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8288 - val_loss: 0.8188\n",
            "Epoch 61/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.7969 - val_loss: 0.8185\n",
            "Epoch 62/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8113 - val_loss: 0.8188\n",
            "Epoch 63/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8212 - val_loss: 0.8183\n",
            "Epoch 64/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8158 - val_loss: 0.8184\n",
            "Epoch 65/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8066 - val_loss: 0.8181\n",
            "Epoch 66/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8069 - val_loss: 0.8182\n",
            "Epoch 67/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8084 - val_loss: 0.8181\n",
            "Epoch 68/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8225 - val_loss: 0.8179\n",
            "Epoch 69/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8297 - val_loss: 0.8179\n",
            "Epoch 70/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8271 - val_loss: 0.8178\n",
            "Epoch 71/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8070 - val_loss: 0.8178\n",
            "Epoch 72/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8179 - val_loss: 0.8176\n",
            "Epoch 73/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8242 - val_loss: 0.8176\n",
            "Epoch 74/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8169 - val_loss: 0.8177\n",
            "Epoch 75/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8242 - val_loss: 0.8175\n",
            "Epoch 76/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8137 - val_loss: 0.8182\n",
            "Epoch 77/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8306 - val_loss: 0.8173\n",
            "Epoch 78/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8237 - val_loss: 0.8173\n",
            "Epoch 79/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8194 - val_loss: 0.8173\n",
            "Epoch 80/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8206 - val_loss: 0.8175\n",
            "Epoch 81/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8155 - val_loss: 0.8177\n",
            "Epoch 82/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8082 - val_loss: 0.8171\n",
            "Epoch 83/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8023 - val_loss: 0.8172\n",
            "Epoch 84/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.7996 - val_loss: 0.8172\n",
            "Epoch 85/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8258 - val_loss: 0.8178\n",
            "Epoch 86/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8081 - val_loss: 0.8172\n",
            "Epoch 87/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8232 - val_loss: 0.8169\n",
            "Epoch 88/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.7985 - val_loss: 0.8168\n",
            "Epoch 89/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8249 - val_loss: 0.8172\n",
            "Epoch 90/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8140 - val_loss: 0.8169\n",
            "Epoch 91/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8085 - val_loss: 0.8167\n",
            "Epoch 92/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8246 - val_loss: 0.8167\n",
            "Epoch 93/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8024 - val_loss: 0.8169\n",
            "Epoch 94/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8195 - val_loss: 0.8166\n",
            "Epoch 95/100\n",
            "1113/1113 [==============================] - 2s 2ms/step - loss: 0.8289 - val_loss: 0.8167\n",
            "Epoch 96/100\n",
            "1113/1113 [==============================] - 3s 2ms/step - loss: 0.8248 - val_loss: 0.8166\n",
            "Epoch 97/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8154 - val_loss: 0.8166\n",
            "Epoch 98/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8148 - val_loss: 0.8165\n",
            "Epoch 99/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8117 - val_loss: 0.8166\n",
            "Epoch 100/100\n",
            "1113/1113 [==============================] - 3s 3ms/step - loss: 0.8096 - val_loss: 0.8164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1b83a1d050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MntASWT9EYJ"
      },
      "source": [
        "encoder_all = Model(input_layer_all,encoded_all)\n",
        "enc_all = encoder_all.predict(X_train)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYRDsZ6ygSJq"
      },
      "source": [
        "Loading library for k-NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iix7bOJQ5gxc"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaDHQXxt5iCg"
      },
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors=3)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjqB805u9XqF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd813449-c05c-4d6b-94d9-a49efd13bad9"
      },
      "source": [
        "# Train the model using the training sets\n",
        "knn_model.fit(enc_all,y_train)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80H7xbeSBvWc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98342208-886f-41e4-a40f-cc9c33ed60c7"
      },
      "source": [
        "%%time\n",
        "knn_predicted= knn_model.predict(encoder_all.predict(X_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 36.8 s, sys: 406 ms, total: 37.2 s\n",
            "Wall time: 38.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aVN3Qe-D3Oz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "c0ef8d3b-c3bc-42ac-b110-4810f8efd33e"
      },
      "source": [
        "conf_matrix = metrics.confusion_matrix(y_test,knn_predicted)\n",
        "\n",
        "ax=plt.subplot()\n",
        "sns.heatmap(conf_matrix,annot=True,ax=ax,fmt='g')#annot=True to annotate cells, fmt='g' numbers not scientific form\n",
        "ax.set_xlabel('Predicted labels'); ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix'); \n",
        "ax.xaxis.set_ticklabels(['Normal', 'Fraud']); ax.yaxis.set_ticklabels(['Normal', 'Fraud']);\n",
        "ax.set(yticks=[0, 2], \n",
        "       xticks=[0.5, 1.5])\n",
        "ax.yaxis.set_major_locator(ticker.IndexLocator(base=1, offset=0.5))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}